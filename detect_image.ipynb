{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des bibliothèques\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer l'architecture et les poids du modèle de détection de visage\n",
    "architecture = r\"face_detector\\deploy.prototxt\"\n",
    "poids = r\"face_detector\\weights.caffemodel\"\n",
    "net = cv2.dnn.readNet(architecture, poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer le model de détection de mask\n",
    "model = load_model(r\"model\\face_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charger l'image d'entrée\n",
    "image =cv2.imread(r\"validation\\1.jpg\")\n",
    "(h, l) = image.shape[:2]\n",
    "# {h:hauteur , l:largeur}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prétraitement d'image\n",
    "blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300,300), mean=(104, 177, 123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenir les détections de visage\n",
    "net.setInput(blob)\n",
    "detection = net.forward()\n",
    "\n",
    "for i in range(detection.shape[2]):\n",
    "    confidence = detection[0, 0, i, 2] \n",
    "    if confidence > 0.5:\n",
    "\n",
    "        #calculer les délimitations de la boîte\n",
    "        boxes = detection[0, 0, i, 3:] * np.array([l,h, l,h]) \n",
    "\n",
    "        (gauche, haut, droite, bas) = boxes.astype('int') \n",
    "      \n",
    "        (gauche, haut) = (max(0, gauche)), max(0, haut) \n",
    "        (droite, bas) = (min(l-1, droite), min(h-1, bas))\n",
    "        \n",
    "        face = image[haut:bas , gauche:droite]\n",
    "\n",
    "      \n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(face, dsize=(224, 224))\n",
    "        face = img_to_array(face)      \n",
    "        face = preprocess_input(face)  \n",
    "        face = np.expand_dims(face, axis=0)              \n",
    "        \n",
    "        (mohamed, other, youssef) = model.predict(face)[0]\n",
    "\n",
    "        # déterminer la classe de chaque prédiction\n",
    "        if mohamed > youssef and mohamed > other:\n",
    "            label = \"mohamed\"\n",
    "            couleur = (0, 255, 0)\n",
    "        elif youssef > mohamed and youssef > other:\n",
    "            label = \"youssef\"\n",
    "            couleur =(0, 255, 0)\n",
    "        else:\n",
    "            label = \"Other\"\n",
    "            couleur = (0, 0, 255)\n",
    "\n",
    "        # tracer un rectangle autour des visages \n",
    "        cv2.rectangle(image, (gauche, haut), (droite, bas), couleur, 2)\n",
    "        # afficher la classe du visage\n",
    "        cv2.putText(image, label, (gauche, haut-15), cv2.FONT_HERSHEY_SIMPLEX, 0.45, couleur, 2)\n",
    "        \n",
    "cv2.imshow(\"output\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('opencv_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb6fa332371bc522d643c7a8521215c7ab9fc77042fe272fd2c96ae478ff98c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
